


# Import libraries 
import pandas as pd
import numpy as np
import csv 
from pathlib import Path


# Calculate the Average of all Cumulative returns 
Data1 = Path("cumulative_returns_data.csv")
cumulative1_df = pd.read_csv(Data1)

Data2 = Path("cumulative_returns_data2.csv")
cumulative2_df = pd.read_csv(Data2)

Data3 = Path("cumulative_returns_data3.csv")
cumulative3_df = pd.read_csv(Data3)

Data4 = Path("cumulative_returns_data4.csv")
cumulative4_df = pd.read_csv(Data4)

Data5 = Path("cumulative_returns_data5.csv")
cumulative5_df = pd.read_csv(Data5)


# Combine all cumulative returns data 
combined_df = pd.concat([cumulative1_df,cumulative2_df,cumulative3_df,cumulative4_df,cumulative5_df], axis='rows')

# Display the combined DataFrame
combined_df.head()


# Assuming df is your DataFrame containing the data
# Extract the "Tech" columns
tech_columns = combined_df.filter(like='Tech')

# Calculate the average of the "Tech" columns
tech_average = tech_columns.mean()

print(tech_average)


# Assuming df is your DataFrame containing the data
# Extract the "Health" columns
health_columns = combined_df.filter(like='Health')

# Calculate the average of the "Tech" columns
health_average = health_columns.mean()

print(health_average)


# Assuming df is your DataFrame containing the data
# Extract the "Finance" columns
finance_columns = combined_df.filter(like='Finance')

# Calculate the average of the "Tech" columns
finance_average = finance_columns.mean()

print(finance_average)


# Assuming df is your DataFrame containing the data
# Extract the "Consumer" columns
consumer_columns = combined_df.filter(like='Consumer')

# Calculate the average of the "Tech" columns
consumer_average = consumer_columns.mean()

print(consumer_average)


# Assuming df is your DataFrame containing the data
# Extract the "Energy" columns
energy_columns = combined_df.filter(like='Energy')

# Calculate the average of the "Tech" columns
energy_average = energy_columns.mean()

print(energy_average)


# Assuming df is your DataFrame containing the data
# Extract the "Weapons" columns
weapons_columns = combined_df.filter(like='Weapons')

# Calculate the average of the "Tech" columns
weapons_average = weapons_columns.mean()

print(weapons_average)








# Initial imports
import os
import requests
import pandas as pd
from dotenv import load_dotenv
import alpaca_trade_api as tradeapi
from MCForecastTools import MCSimulation

%matplotlib inline


# Set start and end dates of five years back from today.
# Sample results may vary from the solution based on the time frame chosen
start_date = pd.Timestamp('2018-10-31', tz='America/New_York').isoformat()
end_date = pd.Timestamp('2023-10-31', tz='America/New_York').isoformat()


# Specify the path to your .env file
dotenv_path = 'api.env'

# Load .env enviroment variables
load_dotenv(dotenv_path)

# Load environment variables
load_dotenv(dotenv_path)

# Access Alpaca API key ID
alpaca_api_key_id = os.getenv("APCA_API_KEY_ID")
alpaca_secret_key = os.getenv("APCA_API_SECRET_KEY")

# Create the Alpaca API object
alpaca = tradeapi.REST(
    alpaca_api_key_id,
    alpaca_secret_key,
    api_version="v2")


# Get 5 years' worth of historical data for SPY and AGG
tickers = ["AAPL","GOOG","MSFT","JNJ","PFE","UNH","JPM","BAC","V"]

timeframe = "1Day"

df_ticker = alpaca.get_bars(
    tickers,
    timeframe,
    start=start_date,
    end=end_date
).df

# Display sample data 
df_ticker.head()


df_ticker.tail(15)


# Reorganize the DataFrame
AAPL = df_ticker[df_ticker['symbol']=='AAPL'].drop('symbol', axis=1)
GOOG = df_ticker[df_ticker['symbol']=='GOOG'].drop('symbol', axis=1)
MSFT = df_ticker[df_ticker['symbol']=='MSFT'].drop('symbol', axis=1)
JNJ = df_ticker[df_ticker['symbol']=='JNJ'].drop('symbol', axis=1)
PFE = df_ticker[df_ticker['symbol']=='PFE'].drop('symbol', axis=1)
UNH = df_ticker[df_ticker['symbol']=='UNH'].drop('symbol', axis=1)
JPM = df_ticker[df_ticker['symbol']=='JPM'].drop('symbol', axis=1)
BAC = df_ticker[df_ticker['symbol']=='BAC'].drop('symbol', axis=1)
V = df_ticker[df_ticker['symbol']=='V'].drop('symbol', axis=1)

# Concatenate the ticker DataFrames
df_ticker = pd.concat([AAPL,GOOG,MSFT,JNJ,PFE,UNH,JPM,BAC,V], axis=1, keys=["AAPL","GOOG","MSFT","JNJ","PFE","UNH","JPM","BAC","V"])

# Display sample data
df_ticker.head()


# Create and empty DataFrame for closing prices
df_closing_prices = pd.DataFrame()

# Fetch the closing prices of KO and TSLA
df_closing_prices["AAPL"] = df_ticker["AAPL"]["close"]
df_closing_prices["GOOG"] = df_ticker["GOOG"]["close"]
df_closing_prices["MSFT"] = df_ticker["MSFT"]["close"]
df_closing_prices["JNJ"] = df_ticker["JNJ"]["close"]
df_closing_prices["PFE"] = df_ticker["PFE"]["close"]
df_closing_prices["UNH"] = df_ticker["UNH"]["close"]
df_closing_prices["JPM"] = df_ticker["JPM"]["close"]
df_closing_prices["BAC"] = df_ticker["BAC"]["close"]
df_closing_prices["V"] = df_ticker["V"]["close"]

# Check for NaN values in the 'V' column
# You need to explain 
v_nan_indices = df_closing_prices['V'].isna()
average_V = df_closing_prices['V'].mean()
df_closing_prices['V'] = df_closing_prices['V'].fillna(average_V)

# If there are NaN values, fill them with the average closing price
#if v_nan_indices.any():
    #average_v_closing_price = df_closing_prices["V"].mean()
    #df_closing_prices.loc[v_nan_indices, "V"] = average_v_closing_price

# Drop the time component of the date
df_closing_prices.index = df_closing_prices.index.date

# Ensure the index is in datetime format
df_closing_prices.index = pd.to_datetime(df_closing_prices.index)

df_closing_prices 


# Configuring a Monte Carlo simulation to forecast 2 years cumulative returns
# Weights for each stock are assumed to be equal 
MC_two_year = MCSimulation(
    portfolio_data = df_ticker,
    num_simulation = 200,
    num_trading_days = 252*2
)


# Printing the simulation input data
MC_two_year.portfolio_data.head()


# Running a Monte Carlo simulation to forecast 2 years cumulative returns
MC_two_year.calc_cumulative_return()


import matplotlib.pyplot as plt

# Set the figure size
plt.figure(figsize=(12, 8))

# Get the matplotlib Axes object
ax = MC_two_year.plot_simulation()

# Customize the plot
for line in ax.lines:
    line.set_linewidth(0.5)  # Adjust line width

# Set title and labels
plt.title('Monte Carlo Simulation of 2-Year Cumulative Returns', fontsize=16)
plt.xlabel('Trading Days', fontsize=14)
plt.ylabel('Portfolio Value', fontsize=14)

# Add grid
plt.grid(True)

# Show plot
plt.show()


# Plot simulation outcomes
line_plot = MC_two_year.plot_simulation()

# Save the plot for future usage
line_plot.get_figure().savefig("MC_two_year_sim_plot.png", bbox_inches="tight")



 # Plot probability distribution and confidence intervals
dist_plot = MC_two_year.plot_distribution()

# Save the plot for future usage
dist_plot.get_figure().savefig('MC_two_year_dist_plot.png',bbox_inches='tight')


# Fetch summary statistics from the Monte Carlo simulation results
tbl = MC_two_year.summarize_cumulative_return()

# Print summary statistics
print(tbl)


# Use the lower and upper `95%` confidence intervals to calculate the range of the possible outcomes of our $100,000 investments in the selected stocks

ci_lower = round(tbl[8]*10000,2)
ci_upper = round(tbl[9]*10000,2)

# Print results
print(f"There is a 95% chance that an initial investment of $100,000 in the portfolio"
      f" over the next 2 years will end within in the range of"
      f" ${ci_lower} and ${ci_upper}")





# Define the list of CSV files corresponding to each midterm
csv_files = ['cumulative_returns_data.csv', 'cumulative_returns_data2.csv', 'cumulative_returns_data3.csv', 'cumulative_returns_data4.csv', 'cumulative_returns_data5.csv']

# Initialize an empty list to store Sharpe ratios
sharpe_ratios = []

#  number of  trading days before each midterm to consider
days_before_midterm = 252

# Loop through each CSV file
for csv_file in csv_files:
    # Load cumulative returns from the current CSV file
    cumulative_returns = pd.read_csv(csv_file)

    # Reset the index for the DataFrame
    cumulative_returns = cumulative_returns.reset_index(drop=True)

    # Calculate the daily returns from cumulative returns
    daily_returns = cumulative_returns.pct_change()

    # Loop through each trading day
    for i in range(len(daily_returns)):
        # Calculate the Sharpe ratio for each asset over the specified period
        start_index = max(0, i - days_before_midterm + 1)
        period_data = daily_returns.iloc[start_index:i+1]
        sharpe_ratio = (period_data.mean() / period_data.std()) * np.sqrt(252)  # Assuming 252 trading days in a year

        # Append Sharpe ratios to the list
        sharpe_ratios.append(sharpe_ratio)

# Convert the list of Sharpe ratios into a DataFrame
sharpe_ratios_df = pd.DataFrame(sharpe_ratios, columns=cumulative_returns.columns)

# Calculate the average Sharpe ratio for each asset
average_sharpe_ratios = sharpe_ratios_df.mean()

# Display the average Sharpe ratio for each asset
print("Average Sharpe Ratios Before Each Midterm:")
print(average_sharpe_ratios)
  


# Create a bar plot for the average Sharpe ratios
plt.figure(figsize=(10, 6))
bars = plt.bar(average_sharpe_ratios.index, average_sharpe_ratios, color='skyblue', alpha=0.7)

# Add labels and numbers on top of each bar
for bar, label in zip(bars, average_sharpe_ratios):
    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.01,
             f'{round(label, 2)}', ha='center', color='black', fontsize=10)
    
# Add labels and title
plt.xlabel('Industry')
plt.ylabel('Average Sharpe Ratio Before Each Midterm')
plt.title('Average Sharpe Ratio for Each Industry before Midterm')

# Show the plot
plt.show()







# Define the list of CSV files corresponding to each midterm
csv_files = ['cumulative_returns_2016_2017_R.csv', 'cumulative_returns_2018_2019_R.csv', 'cumulative_returns_2020_2021_D.csv', 'cumulative_returns_2022_2023_D.csv',]

# Initialize an empty list to store Sharpe ratios
sharpe_ratios = []

# Define the number of days after each midterm to consider
days_after_midterm = 252

# Loop through each CSV file
for csv_file in csv_files:
    # Load cumulative returns from the current CSV file
    cumulative_returns = pd.read_csv(csv_file)

    # Reset the index for the DataFrame
    cumulative_returns = cumulative_returns.reset_index(drop=True)

    # Calculate the daily returns from cumulative returns
    daily_returns = cumulative_returns.pct_change()

    # Loop through each trading day
    for i in range(len(daily_returns)):
        # Calculate the Sharpe ratio for each asset over the specified period
        start_index = max(0, i - days_before_midterm + 1)
        period_data = daily_returns.iloc[start_index:i+1]
        sharpe_ratio = (period_data.mean() / period_data.std()) * np.sqrt(252)  # Assuming 252 trading days in a year

        # Append Sharpe ratios to the list
        sharpe_ratios.append(sharpe_ratio)

# Convert the list of Sharpe ratios into a DataFrame
sharpe_ratios_df = pd.DataFrame(sharpe_ratios, columns=cumulative_returns.columns)

# Calculate the average Sharpe ratio for each asset
average_sharpe_ratios = sharpe_ratios_df.mean()

# Display the average Sharpe ratio for each asset
print("Average Sharpe Ratios After Each Midterm:")
print(average_sharpe_ratios)


# Create a bar plot for the average Sharpe ratios
plt.figure(figsize=(10, 6))
bars = plt.bar(average_sharpe_ratios.index, average_sharpe_ratios, color='skyblue', alpha=0.7)

# Add labels and numbers on top of each bar
for bar, label in zip(bars, average_sharpe_ratios):
    plt.text(bar.get_x() + bar.get_width() / 2 - 0.1, bar.get_height() + 0.01,
             f'{round(label, 2)}', ha='center', color='black', fontsize=10)
    
# Add labels and title
plt.xlabel('Industry')
plt.ylabel('Average Sharpe Ratio')
plt.title('Average Sharpe Ratio for Each Industry after Midterm')

# Show the plot
plt.show()



